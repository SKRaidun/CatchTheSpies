{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5100a6c5-a6f0-4c5d-9787-b5d99c2ab45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('PointzAggregator-AirlinesData.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "def parse_users(root):\n",
    "    data = []\n",
    "\n",
    "    for user in root.findall('user'):\n",
    "        user_uid = user.attrib.get('uid')\n",
    "        first_name = user.find('name').attrib.get('first')\n",
    "        last_name = user.find('name').attrib.get('last')\n",
    "\n",
    "        for card in user.findall('.//card'):\n",
    "            card_number = card.attrib.get('number')\n",
    "            bonus_program = card.find('bonusprogramm').text\n",
    "\n",
    "            for activity in card.findall('.//activity'):\n",
    "                activity_data = {\n",
    "                    'user_uid': user_uid,\n",
    "                    'first_name': first_name,\n",
    "                    'last_name': last_name,\n",
    "                    'card_number': card_number,\n",
    "                    'bonus_program': bonus_program,\n",
    "                    'activity_code': activity.find('Code').text,\n",
    "                    'activity_date': activity.find('Date').text,\n",
    "                    'departure': activity.find('Departure').text,\n",
    "                    'arrival': activity.find('Arrival').text,\n",
    "                    'fare': activity.find('Fare').text,\n",
    "                }\n",
    "                data.append(activity_data)\n",
    "\n",
    "    return data\n",
    "\n",
    "user_data = parse_users(root)\n",
    "df_xml = pd.DataFrame(user_data)\n",
    "df_xml.to_csv('PointzAggregator-AirlinesData.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce6a96-3ff0-483b-8fb3-e616159dae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from ruamel.yaml import YAML\n",
    "yaml = YAML(typ='safe')\n",
    "\n",
    "def process_large_yaml(file_path):\n",
    "    data = []\n",
    "    buf = ''\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if re.search(r'\\d{4}-\\d{2}-\\d{2}', line):\n",
    "                if buf:\n",
    "                    daily_data = yaml.load_all(buf)\n",
    "                    for daily_entry in daily_data:\n",
    "                        data.append(daily_entry)\n",
    "                    buf = ''\n",
    "            buf += line\n",
    "\n",
    "        if buf:\n",
    "            daily_data = yaml.load_all(buf)\n",
    "            for daily_entry in daily_data:\n",
    "                data.append(daily_entry)\n",
    "\n",
    "    flattened_data = []\n",
    "    for entry in data:\n",
    "        for date, flights in entry.items():\n",
    "            for flight_num, flight_info in flights.items():\n",
    "                if 'FF' in flight_info:\n",
    "                    for ff_num, ff_data in flight_info['FF'].items():\n",
    "                        row = {\n",
    "                            'Date': date,\n",
    "                            'Flight': flight_num,\n",
    "                            'FF Number': ff_num,\n",
    "                            'Class': ff_data['CLASS'],\n",
    "                            'Fare': ff_data['FARE'],\n",
    "                            'From': flight_info['FROM'],\n",
    "                            'To': flight_info['TO'],\n",
    "                            'Status': flight_info['STATUS']\n",
    "                        }\n",
    "                        flattened_data.append(row)\n",
    "\n",
    "    return flattened_data\n",
    "\n",
    "df = pd.DataFrame(process_large_yaml('SkyTeam-Exchange.yaml'))\n",
    "df.to_csv(\"SkyTeam-Exchange.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb8227-b730-49f2-b7fa-cb7ae937899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transliterate import translit\n",
    "file1 = open('Sirena-export-fixed.tab', mode='r', encoding='utf-8')\n",
    "file2 = open('Sirena-export-fixed.csv', mode='w', encoding='utf-8')\n",
    "heading = \",\".join(file1.readline().split()[:-2])\n",
    "file2.write(heading)\n",
    "file2.write('\\n')\n",
    "list_str = file1.readlines()\n",
    "\n",
    "for s in list_str:\n",
    "    new_s = []\n",
    "    s = s.split()\n",
    "    new_s.append(translit(\" \".join(s[0:3]), language_code='ru', reversed=True))\n",
    "    new_s.append(\",\".join(s[3:8]))\n",
    "    new_s.append(s[8][:6])\n",
    "    new_s.append(s[8][6:])\n",
    "    new_s.append(\",\".join(s[9:11]))\n",
    "    new_s.append(s[11][:6])\n",
    "    new_s.append(s[11][6:])\n",
    "    new_s.append(\" \".join(s[12:14]))\n",
    "    new_s.append(s[14])\n",
    "    if len(s[15]) == 1:\n",
    "        s.insert(15, \" \")\n",
    "    new_s.append(\",\".join(s[15:17]))\n",
    "    new_s.append(s[17][:6])\n",
    "    if len(s[17]) == 6:\n",
    "        new_s.append(\" \")\n",
    "    else:\n",
    "        new_s.append(s[17][6:])\n",
    "    clean_s = \",\".join(new_s)\n",
    "    file2.write(clean_s)\n",
    "    file2.write('\\n')\n",
    "\n",
    "file1.close()\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe72d5c-0d1a-45ac-8630-cce804b6577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_json = pd.read_json('FrequentFlyerForum-Profiles.json')\n",
    "\n",
    "normal_df = pd.json_normalize(df_json[\"Forum Profiles\"])\n",
    "\n",
    "exploded_df = normal_df.explode(\"Registered Flights\", ignore_index = True).explode(\"Travel Documents\", ignore_index = True).explode(\"Loyality Programm\", ignore_index = True)\n",
    "\n",
    "RegFli_df = pd.json_normalize(exploded_df[\"Registered Flights\"])\n",
    "RegFli_df.columns = ['Date', 'CodeShare', 'Flight', 'ArrCity', 'ArrAirport', 'ArrCountry', 'DepCity', 'DepAirport', 'DepCountry']\n",
    "\n",
    "TravDoc_df = pd.json_normalize(exploded_df[\"Travel Documents\"])\n",
    "\n",
    "LoyalProg_df = pd.json_normalize(exploded_df[\"Loyality Programm\"])\n",
    "LoyalProg_df.columns = ['Status', 'LoyalProgramm', 'LoyalProgNumber']\n",
    "\n",
    "exploded_df = exploded_df.drop(['Registered Flights', 'Travel Documents', 'Loyality Programm'], axis = 1)\n",
    "exploded_df.columns = ['NickName', 'Sex', 'Last Name', 'First Name']\n",
    "\n",
    "df = pd.concat([exploded_df, RegFli_df, TravDoc_df, LoyalProg_df], axis = 1)\n",
    "\n",
    "df.to_csv(\"FrequentFlyerForum-Profiles.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daff0336-8d47-4f68-8169-4de1e0eebe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('YourBoardingPassDotAero.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af53bf4-9618-4d13-8e80-11e17c265fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "file_paths = glob.glob(\"*.xlsx\")\n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e04e14-065c-4628-8c37-327d4e391de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing(file_path):\n",
    "\n",
    "    xlsx_data = pd.ExcelFile(file_path)\n",
    "\n",
    "    extracted_data = []\n",
    "\n",
    "    for sheet in xlsx_data.sheet_names:\n",
    "        try:\n",
    "\n",
    "            df = pd.read_excel(xlsx_data, sheet_name=sheet, header=None)\n",
    "\n",
    "            name = f\"{df.iloc[2, 0]} {df.iloc[2, 1]}\"\n",
    "            sequence = df.iloc[0, 7]\n",
    "            passenger_class = df.iloc[2, 7]\n",
    "            flight = df.iloc[4, 0]\n",
    "            from_city = df.iloc[4, 3]\n",
    "            to_city = df.iloc[4, 7]\n",
    "            from_airport = df.iloc[6, 3]\n",
    "            to_airport = df.iloc[6, 7]\n",
    "            gate = df.iloc[6, 1]\n",
    "            date = df.iloc[8, 0]\n",
    "            time = df.iloc[8, 2]\n",
    "            carrier = df.iloc[8, 4]\n",
    "            seat = df.iloc[10, 7]\n",
    "            pnr = df.iloc[12, 1]\n",
    "            e_ticket = df.iloc[12, 4]\n",
    "\n",
    "            extracted_data.append({\n",
    "                \"NAME\": name,\n",
    "                \"SEQUENCE\": sequence,\n",
    "                \"CLASS\": passenger_class,\n",
    "                \"FLIGHT\": flight,\n",
    "                \"FROM\": from_city,\n",
    "                \"TO\": to_city,\n",
    "                \"FROMAIR\": from_airport,\n",
    "                \"TOAIR\": to_airport,\n",
    "                \"GATE\": gate,\n",
    "                \"DATE\": date,\n",
    "                \"TIME\": time,\n",
    "                \"CARRIER\": carrier,\n",
    "                \"SEAT\": seat,\n",
    "                \"PNR\": pnr,\n",
    "                \"E-TICKET\": e_ticket\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sheet {sheet}: {e}\")\n",
    "\n",
    "    passengers_df = df.DataFrame(extracted_data)\n",
    "\n",
    "    return passengers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ee6e14-65ea-4d23-b135-4e0ead8dcbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask\n",
    "import dask.bag as db\n",
    "import cudf\n",
    "\n",
    "bag = db.from_sequence(file_paths, npartitions=10).map(parsing)\n",
    "\n",
    "all_data = bag.compute()\n",
    "\n",
    "final_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "\n",
    "final_df.to_csv(\"passenger_info(ZIP).csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104f3a3a-227c-45d2-8123-f26997e55ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import pdfplumber\n",
    "from pdfminer.high_level import extract_pages, extract_text\n",
    "from pdfminer.layout import LTTextContainer, LTChar, LTRect, LTFigure\n",
    "from PIL import Image\n",
    "import os\n",
    "pdf_path = 'Skyteam_Timetable.pdf'\n",
    "import fitz  \n",
    "from pathlib import Path\n",
    "\n",
    "def split_pdf_vertically(input_pdf, output_left, output_right):\n",
    "\n",
    "    pdf = fitz.open(input_pdf)\n",
    "\n",
    "    num_pages = pdf.page_count\n",
    "\n",
    "    pdf_left = fitz.open()\n",
    "    pdf_right = fitz.open()\n",
    "\n",
    "    for i in range(4, num_pages):\n",
    "        page = pdf.load_page(i)\n",
    "        rect = page.rect  \n",
    "\n",
    "        left_rect = fitz.Rect(rect.x0, rect.y0, rect.width / 2, rect.y1)\n",
    "        right_rect = fitz.Rect(rect.width / 2, rect.y0, rect.x1, rect.y1)\n",
    "\n",
    "        left_page = pdf_left.new_page(width=left_rect.width, height=left_rect.height)\n",
    "        right_page = pdf_right.new_page(width=right_rect.width, height=right_rect.height)\n",
    "\n",
    "        left_page.show_pdf_page(left_page.rect, pdf, i, clip=left_rect)\n",
    "        right_page.show_pdf_page(right_page.rect, pdf, i, clip=right_rect)\n",
    "\n",
    "    pdf_left.save(output_left)\n",
    "    pdf_right.save(output_right)\n",
    "\n",
    "    pdf.close()\n",
    "    pdf_left.close()\n",
    "    pdf_right.close()\n",
    "\n",
    "split_pdf_vertically(pdf_path, \"new_left_tables.pdf\", \"new_right_tables.pdf\")\n",
    "\n",
    "import fitz  \n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "MONTHS = {\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \n",
    "          \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"}\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with fitz.open(pdf_path) as pdf:\n",
    "        texts = [page.get_text() for page in pdf]\n",
    "    return texts\n",
    "\n",
    "def is_month(text):\n",
    "    return any(text.endswith(month) for month in MONTHS)\n",
    "\n",
    "def safe_get_line(lines, index):\n",
    "    return lines[index].strip() if index < len(lines) else None\n",
    "\n",
    "def parse_flights(text, current_from=None, current_to=None):\n",
    "    from_pattern = r\"FROM:\\s*(.+),\\s*(.+)\"\n",
    "    flight_data = []\n",
    "    lines = text.splitlines()\n",
    "    i = 0\n",
    "\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "\n",
    "        # Обработка FROM\n",
    "        from_match = re.match(from_pattern, line)\n",
    "        if from_match:\n",
    "            airport_city = f\"{from_match.group(1).strip()}\"\n",
    "            airport_country = f\"{from_match.group(2).strip()}\"\n",
    "            airport_code = safe_get_line(lines, i + 1)  # Получаем код аэропорта\n",
    "            current_from = f\"{airport_city}, {airport_country}, {airport_code}\"  # Добавляем код аэропорта к названию\n",
    "            i += 2  # Пропускаем строку с кодом аэропорта\n",
    "            continue\n",
    "\n",
    "        # Обработка TO\n",
    "        if line.startswith(\"TO:\"):\n",
    "            i += 1\n",
    "            to_city = safe_get_line(lines, i)\n",
    "            i += 1\n",
    "            to_country = safe_get_line(lines, i)\n",
    "            current_to = f\"{to_city}, {to_country}\"\n",
    "            i += 1  \n",
    "            continue\n",
    "\n",
    "        if line in [\"Validity\", \"Days\", \"Dep\", \"Time\", \"Arr\", \"Flight\", \"Aircraft\", \"Travel\", \"Time\"]:\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        validity = line.strip()\n",
    "        if not is_month(validity.split()[-1]):  # Если Validity содержит Days\n",
    "            days = validity\n",
    "            dep_time = safe_get_line(lines, i + 1)\n",
    "            arr_time = safe_get_line(lines, i + 2)\n",
    "            flight = safe_get_line(lines, i + 3)\n",
    "            aircraft = safe_get_line(lines, i + 4)\n",
    "            travel_time = safe_get_line(lines, i + 5)\n",
    "            i += 6\n",
    "        else:  # Если Validity не содержит Days\n",
    "            days = safe_get_line(lines, i + 1)\n",
    "            if ':' in days:  # Если Days содержит DepTime\n",
    "                dep_time = days\n",
    "                days = None\n",
    "                arr_time = safe_get_line(lines, i + 2)\n",
    "                flight = safe_get_line(lines, i + 3)\n",
    "                aircraft = safe_get_line(lines, i + 4)\n",
    "                travel_time = safe_get_line(lines, i + 5)\n",
    "                i += 6\n",
    "            else:\n",
    "                dep_time = safe_get_line(lines, i + 2)\n",
    "                arr_time = safe_get_line(lines, i + 3)\n",
    "                flight = safe_get_line(lines, i + 4)\n",
    "                aircraft = safe_get_line(lines, i + 5)\n",
    "                travel_time = safe_get_line(lines, i + 6)\n",
    "                i += 7\n",
    "\n",
    "        if not days:  # Если days пустое\n",
    "            dep_time = dep_time.strip()  # Убираем лишние пробелы\n",
    "            days, dep_time = dep_time[:-5].strip(), dep_time[-5:].strip()\n",
    "\n",
    "        # Если какое-то поле пустое, добавляем сообщение \"Consult your travel agent\"\n",
    "        entry = {\n",
    "            \"FROM\": current_from or \"Consult your travel agent\",\n",
    "            \"TO\": current_to or \"Consult your travel agent\",\n",
    "            \"Validity\": validity or \"Consult your travel agent\",\n",
    "            \"Days\": days or \"Consult your travel agent\",\n",
    "            \"DepTime\": dep_time or \"Consult your travel agent\",\n",
    "            \"ArrTime\": arr_time or \"Consult your travel agent\",\n",
    "            \"Flight\": flight or \"Consult your travel agent\",\n",
    "            \"Aircraft\": aircraft or \"Consult your travel agent\",\n",
    "            \"TravelTime\": travel_time or \"Consult your travel agent\",\n",
    "        }\n",
    "        flight_data.append(entry)\n",
    "\n",
    "    return flight_data\n",
    "\n",
    "def process_pdf_files(left_pdf, right_pdf):\n",
    "    \"\"\"Обрабатывает два PDF и возвращает объединенный DataFrame.\"\"\"\n",
    "    left_texts = extract_text_from_pdf(left_pdf)\n",
    "    right_texts = extract_text_from_pdf(right_pdf)\n",
    "\n",
    "    all_flight_data = []\n",
    "    current_from, current_to = None, None\n",
    "\n",
    "    # Обработка левого PDF\n",
    "    for text in left_texts:\n",
    "        flights = parse_flights(text, current_from, current_to)\n",
    "        if flights:\n",
    "            current_from = flights[-1][\"FROM\"]\n",
    "            current_to = flights[-1][\"TO\"]\n",
    "        all_flight_data.extend(flights)\n",
    "\n",
    "    # Обработка правого PDF\n",
    "    for text in right_texts:\n",
    "        flights = parse_flights(text, current_from, current_to)\n",
    "        if flights:\n",
    "            current_from = flights[-1][\"FROM\"]\n",
    "            current_to = flights[-1][\"TO\"]\n",
    "        all_flight_data.extend(flights)\n",
    "\n",
    "    # Создаем DataFrame\n",
    "    return pd.DataFrame(all_flight_data)\n",
    "\n",
    "# Пример использования\n",
    "left_pdf_path = \"left_tables.pdf\"\n",
    "right_pdf_path = \"right_tables.pdf\"\n",
    "\n",
    "df = process_pdf_files(left_pdf_path, right_pdf_path)\n",
    "\n",
    "# Сохранение результата в CSV\n",
    "df.to_csv(\"flights_data(PDF).csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
